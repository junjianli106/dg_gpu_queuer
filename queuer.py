import json
from nvitop import select_devices
import time
import os
import datetime
from redis import Redis

def set_config_gpus(config):
    redis_client = RedisClient()
    if config.use_gpu and isinstance(config.visible_cuda, str) and 'auto_select_' in config.visible_cuda:
        # å¦‚æœæ˜¯è‡ªåŠ¨é€‰æ‹©GPU
        min_count = int(config.visible_cuda.split('auto_select_')[-1])
        gpus = select_devices(format='index', min_count=min_count,
                              min_free_memory=config.cuda_min_free_memory,
                              max_memory_utilization=config.cuda_max_memory_utilization)
        self_occupied_gpus = redis_client.get_self_occupied_gpus()
        available_gpus = list(set(gpus) - self_occupied_gpus)
        if len(available_gpus) > 0 and len(available_gpus) >= min_count:
            # æœ‰è¶³å¤Ÿå¯ç”¨GPU
            config.wait_gpus = False
            config.visible_cuda = available_gpus[:min_count]
            if isinstance(available_gpus, int):
                config.default_device = f'cuda:{available_gpus}'
            else:
                config.default_device = f'cuda:{available_gpus[0]}'
            redis_client.register_gpus(config)
            print(f"è‡ªåŠ¨é€‰æ‹©GPUï¼š{str(config.visible_cuda)}")
        else:
            # å¯ç”¨GPUä¸è¶³
            if config.wait_gpus:
                # æ’é˜Ÿ
                config.task_id = redis_client.join_wait_queue(config)
            else:
                # ä¸æ’é˜Ÿ
                raise Exception("å¯ç”¨GPUæ•°é‡ä¸è¶³ï¼Œå»ºè®®ä½¿ç”¨æ’é˜ŸåŠŸèƒ½ï¼")
    elif config.use_gpu:
        # å¦‚æœæŒ‡å®šäº†GPU
        reserve_gpus = config.visible_cuda
        min_count = len(reserve_gpus)
        self_occupied_gpus = redis_client.get_self_occupied_gpus()
        gpu_all_free = True
        for gpu in reserve_gpus:
            if gpu in self_occupied_gpus:
                gpu_all_free = False
        if not config.wait_gpus and not gpu_all_free:
            raise Exception("æŒ‡å®šGPUå¹¶æœªå…¨éƒ¨ç©ºé—²ï¼Œå»ºè®®ä½¿ç”¨æ’é˜ŸåŠŸèƒ½ï¼")
        elif gpu_all_free:
            available_gpus = reserve_gpus
            config.wait_gpus = False
            config.visible_cuda = available_gpus[:min_count]
            if isinstance(available_gpus, int):
                config.default_device = f'cuda:{available_gpus}'
            else:
                config.default_device = f'cuda:{available_gpus[0]}'
            redis_client.register_gpus(config)
        else:
            # æ’é˜Ÿ
            config.task_id = redis_client.join_wait_queue(config)
    else:
        # ä½¿ç”¨CPU
        config.default_device = f'cpu'
        config.wait_gpus = False
        config.visible_cuda = []

    ###############################################
    # æ£€æŸ¥æ˜¯å¦éœ€è¦ç­‰å¾…Gpu
    ###############################################
    while config.use_gpu and config.wait_gpus:
        # åˆ¤æ–­å½“å‰æ˜¯å¦è½®åˆ°è‡ªå·±
        if redis_client.is_my_turn(config):
            # å¾ªç¯è·å–å½“å‰å¯ç”¨Gpu
            try:
                min_count = int(config.visible_cuda.split('auto_select_')[-1]) if isinstance(config.visible_cuda, str) and "auto_select_" in config.visible_cuda else len(config.visible_cuda)
                gpus = select_devices(format='index', min_count=min_count,
                                      min_free_memory=config.cuda_min_free_memory,max_memory_utilization=config.cuda_max_memory_utilization)
                self_occupied_gpus = redis_client.get_self_occupied_gpus()
                if not isinstance(config.visible_cuda, str):
                    # å¦‚æœæŒ‡å®šäº†GPU
                    reserve_gpus = config.visible_cuda
                    gpu_all_free = True
                    for gpu in reserve_gpus:
                        if gpu in self_occupied_gpus:
                            gpu_all_free = False
                    if gpu_all_free:
                        available_gpus = reserve_gpus
                    else:
                        available_gpus = []
                    min_count = len(reserve_gpus)
                else:
                    # è‡ªåŠ¨é€‰æ‹©
                    available_gpus = list(set(gpus) - self_occupied_gpus)

                if len(available_gpus) > 0 and len(available_gpus) >= min_count:
                    # è‡ªåŠ¨é€‰æ‹©ï¼Œç¡®è®¤ç­‰å¾…
                    if config.confirm_gpu_free and config.last_confirm_gpus == available_gpus[:min_count]:
                        # å¦‚æœæ»¡è¶³æ¡ä»¶é€€å‡ºå¾ªç¯
                        print("å‘ç°è¶³å¤Ÿå¯ç”¨GPUå¹¶äºŒæ¬¡ç¡®è®¤æˆåŠŸï¼")
                        config.wait_gpus = False
                        config.visible_cuda = available_gpus[:min_count]
                        if isinstance(available_gpus, int):
                            config.default_device = f'cuda:{available_gpus}'
                        else:
                            config.default_device = f'cuda:{available_gpus[0]}'
                        redis_client.pop_wait_queue(config)
                        redis_client.register_gpus(config)
                        break
                    else:
                        # è®¾ç½®å•æ¬¡ç¡®è®¤ç©ºé—²
                        print("å‘ç°è¶³å¤Ÿå¯ç”¨GPUï¼å³å°†è¿›è¡ŒäºŒæ¬¡ç¡®è®¤ï¼")
                        config.confirm_gpu_free = True
                        config.last_confirm_gpus = available_gpus[:min_count]
                        redis_client.update_queue(config)
                        time.sleep(30)
                        continue
                # é‡ç½®ç¡®è®¤ä¿¡æ¯
                print("å½“å‰æ— è¶³å¤Ÿå¯ç”¨GPUï¼Œç»§ç»­ç­‰å¾…......")
                if config.confirm_gpu_free:
                    print("äºŒæ¬¡ç¡®è®¤å¤±è´¥ï¼Œç»§ç»­ç­‰å¾…......")
                config.confirm_gpu_free = False
                config.last_confirm_gpus = []
                redis_client.update_queue(config)
                time.sleep(30)
            except Exception as e:
                print(e)
        else:
            # æ’é˜Ÿing......
            wait_num = len(redis_client.client.lrange('wait_queue', 0, -1)) - 1
            print(f"æ­£åœ¨æ’é˜Ÿä¸­ï¼ å‰æ–¹è¿˜æœ‰ {wait_num} ä¸ªè®­ç»ƒä»»åŠ¡ï¼")
            time.sleep(60)

    return config


class RedisClient:
    def __init__(self):
        self.client = Redis(host='127.0.0.1',
                              port=6379,
                              decode_responses=True,
                              charset='UTF-8',
                              encoding='UTF-8')

    def get_self_occupied_gpus(self, only_gpus=True):
        """
        è·å–è‡ªå·±å·²ç»å ç”¨çš„Gpuåºå·
        """
        self_occupied_gpus = self.client.hgetall('self_occupied_gpus')
        if only_gpus:
            all_gpus = []
            for task in self_occupied_gpus.values():
                gpus = [int(device) for device in json.loads(task)["use_gpus"].split(",")]
                all_gpus.extend(gpus)
            return set(all_gpus)
        return [json.loads(g) for g in self_occupied_gpus.values()]

    def join_wait_queue(self, config):
        """
        åŠ å…¥ç­‰å¾…é˜Ÿåˆ—
        """
        curr_time = datetime.datetime.now()
        creat_time = datetime.datetime.strftime(curr_time, '%Y-%m-%d %H:%M:%S')
        task_id = str(os.getpid()) + '*' + str(int(time.mktime(time.strptime(creat_time, "%Y-%m-%d %H:%M:%S"))))
        content = {
            "create_time": creat_time,
            "update_time": creat_time,
            "system_pid": os.getpid(),
            "task_id": task_id,
        }
        wait_num = len(self.client.lrange('wait_queue', 0, -1))
        self.client.rpush("wait_queue", json.dumps(content))
        if wait_num == 0:
            print(f"æ­£åœ¨æ’é˜Ÿä¸­ï¼ ç›®å‰æ’ç¬¬ä¸€ä½å“¦ï¼")
        else:
            print(f"æ­£åœ¨æ’é˜Ÿä¸­ï¼ å‰æ–¹è¿˜æœ‰ {wait_num} ä¸ªè®­ç»ƒä»»åŠ¡ï¼")
        print(f"tips: å¦‚æœæƒ³è¦å¯¹ä»»åŠ¡è¿›è¡Œè°ƒæ•´å¯ä»¥ç§»æ­¥Rediså®¢æˆ·ç«¯è¿›è¡Œæ•°æ®ä¿®æ”¹ï¼Œåªå»ºè®®è¿›è¡Œä¿®æ”¹ want_gpus å‚æ•°ä»¥åŠåˆ é™¤è®­ç»ƒä»»åŠ¡æ“ä½œï¼Œå…¶ä»–æ“ä½œå¯èƒ½ä¼šå½±å“Redisè¯»å–çš„ç¨³å®šæ€§")
        return task_id

    def is_my_turn(self, config):
        """
        æ’é˜Ÿè¿™ä¹ˆé•¿æ—¶é—´ï¼Œæ˜¯å¦è½®åˆ°æˆ‘äº†ï¼Ÿ
        """
        curr_task = json.loads(self.client.lrange('wait_queue', 0, -1)[0])
        return curr_task['task_id'] == config.task_id

    def update_queue(self, config):
        """
        æ›´æ–°ç­‰å¾…é˜Ÿåˆ—
        """
        task = json.loads(self.client.lrange('wait_queue', 0, -1)[0])
        if task['task_id'] != config.task_id:
            # ç™»è®°å¼‚å¸¸ä¿¡æ¯
            print("å½“å‰è®­ç»ƒä»»åŠ¡å¹¶ä¸æ’åœ¨é˜Ÿåˆ—ç¬¬ä¸€ä½ï¼Œè¯·æ£€æŸ¥Redisæ•°æ®æ­£ç¡®æ€§ï¼")
        curr_time = datetime.datetime.now()
        update_time = datetime.datetime.strftime(curr_time, '%Y-%m-%d %H:%M:%S')
        task['update_time'] = update_time
        self.client.lset("wait_queue", 0, json.dumps(task))
        print("æ›´æ–°è®­ç»ƒä»»åŠ¡æ—¶é—´æˆ³æˆåŠŸï¼")

    def pop_wait_queue(self, config):
        """
        å¼¹å‡ºå½“å‰æ’ä½ç¬¬ä¸€çš„è®­ç»ƒä»»åŠ¡
        """
        task = json.loads(self.client.lrange('wait_queue', 0, -1)[0])
        if task['task_id'] != config.task_id:
            # ç™»è®°å¼‚å¸¸ä¿¡æ¯
            print("å½“å‰è®­ç»ƒä»»åŠ¡å¹¶ä¸æ’åœ¨é˜Ÿåˆ—ç¬¬ä¸€ä½ï¼Œè¯·æ£€æŸ¥Redisæ•°æ®æ­£ç¡®æ€§ï¼")
        next_task = self.client.lpop("wait_queue")
        return next_task

    def register_gpus(self, config):
        """
        å°†å½“å‰è®­ç»ƒä»»åŠ¡ç™»è®°åˆ°GPUå ç”¨ä¿¡æ¯ä¸­
        """
        curr_time = datetime.datetime.now()
        creat_time = datetime.datetime.strftime(curr_time, '%Y-%m-%d %H:%M:%S')
        if not config.task_id:
            task_id = str(os.getpid()) + '*' + str(int(time.mktime(time.strptime(creat_time, "%Y-%m-%d %H:%M:%S"))))
        else:
            task_id = config.task_id
        content = {
            "use_gpus": ','.join([str(gpu) for gpu in list(config.visible_cuda)]),
            "register_time": datetime.datetime.strftime(curr_time,
                                                        '%Y-%m-%d %H:%M:%S'),
            "system_pid": os.getpid(),
            "task_id": task_id,
        }
        self.client.hset("self_occupied_gpus", task_id, json.dumps(content))
        print("æˆåŠŸç™»è®°Gpuä½¿ç”¨ä¿¡æ¯åˆ°RedisæœåŠ¡å™¨ï¼")

    def deregister_gpus(self, config):
        """
        åˆ é™¤å½“å‰è®­ç»ƒä»»åŠ¡çš„å ç”¨ä¿¡æ¯
        """
        task = self.client.hget("self_occupied_gpus", config.task_id)
        if task:
            self.client.hdel("self_occupied_gpus", config.task_id)
            print("æˆåŠŸåˆ é™¤RedisæœåŠ¡å™¨ä¸Šçš„Gpuä½¿ç”¨ä¿¡æ¯ï¼")
        else:
            print("æ— æ³•æ‰¾åˆ°å½“å‰è®­ç»ƒä»»åŠ¡åœ¨RedisæœåŠ¡å™¨ä¸Šçš„Gpuä½¿ç”¨ä¿¡æ¯ï¼æˆ–è®¸å¯ä»¥è€ƒè™‘æ£€æŸ¥ä¸€ä¸‹Redisçš„æ•°æ® ğŸ¤”")

class Config:

    use_gpu = True
    wait_gpus = True  # æ˜¯å¦æ„¿æ„æ¥å—æ’é˜Ÿç­‰å¾…
    cuda_max_memory_utilization = 0.2  # nvitopçš„gpuæœ€å¤§å†…å­˜ä½¿ç”¨é˜ˆå€¼
    cuda_min_free_memory = "35GiB"  # nvitopçš„gpuæœ€å¤§å†…å­˜ä½¿ç”¨é‡
    visible_cuda = 'auto_select_1'  # ä½¿ç”¨â€œauto_select_[æƒ³è¦ä½¿ç”¨çš„GPUæ•°é‡]â€å‰ç¼€è‡ªåŠ¨é€‰æ‹©å¯ç”¨GPUï¼Œæˆ–è€…ä½¿ç”¨åˆ—è¡¨æŒ‡å®šGPU
    # visible_cuda = [1, 2, 3, 6]  # ä½¿ç”¨â€œauto_select_[æƒ³è¦ä½¿ç”¨çš„GPUæ•°é‡]â€å‰ç¼€è‡ªåŠ¨é€‰æ‹©å¯ç”¨GPUï¼Œæˆ–è€…ä½¿ç”¨åˆ—è¡¨æŒ‡å®šGPU

    # ä»¥ä¸‹ä¸ºè‡ªåŠ¨è°ƒæ•´å‚æ•°ï¼Œæ— éœ€æ‰‹åŠ¨æ”¹
    default_device = "cuda:0"  # ç¨‹åºè‡ªåŠ¨è°ƒæ•´ï¼Œé»˜è®¤çš„è®¾å¤‡
    task_id = None  # ç¨‹åºè‡ªåŠ¨è°ƒæ•´ï¼Œå¦‚æœé€‰æ‹©ç­‰å¾…GPUï¼Œé‚£ä¹ˆè¿™å°†æ˜¯æ’é˜Ÿçš„å·ï¼Œæ­¤å¤„æ— éœ€å¡«å†™ï¼Œç”±ç¨‹åºè‡ªåŠ¨ç”Ÿæˆ
    confirm_gpu_free = False  # ç¨‹åºè‡ªåŠ¨è°ƒæ•´ï¼Œç”¨äºæ ‡è¯†å½“å‰è®­ç»ƒä»»åŠ¡æ˜¯å¦å·²ç»ç¡®è®¤äº†GPUå‡ºäºç©ºé—²ï¼Œå¦‚æœä¸¤æ¬¡éƒ½ç­‰åˆ°äº†ç›¸åŒçš„GPUé‚£ä¹ˆå°±è®¤ä¸ºè¯¥GPUç©ºé—²
    last_confirm_gpus = None  # ç¨‹åºè‡ªåŠ¨è°ƒæ•´ï¼Œè®°å½•ç¬¬ä¸€æ¬¡ç¡®è®¤ç©ºé—²çš„gpus

if __name__ == '__main__':
    config = Config()
    config = set_config_gpus(config)
    print()

